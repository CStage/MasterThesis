# -*- coding: utf-8 -*-
"""GAN(G).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ixFBKXfum2k6uieCbeaMEx74pgRyGO4N

# Mount drive
"""

"""# Imports"""
import torch
from torch.utils.data import Dataset, DataLoader
from torch import nn, optim
import torch.nn.functional as F
from torch.autograd.variable import Variable
from torchvision import transforms
import random
import numpy as np
import h5py
import matplotlib.pyplot as plt
from datetime import datetime
import os
import sys
import csv
csv.field_size_limit(sys.maxsize)

transform = transforms.Compose(
    [transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])


"""# Dataset"""
# Current version used for testing the set up
class FiskeSet_test(Dataset):
    def __init__(self, anchors, positives, seed, amount, transform=None):
        random.seed(seed)
        if amount <= 1:
            raise Exception("Amount of samples must be greater than 1 or negatives cannot be fetched.")

        self.anchors = anchors
        self.positives = positives
        self.transform = transform
        self.amount = amount

    def __len__(self):
        return self.amount

    def __getitem__(self, idx):
        anchor = self.anchors[idx]
        positive = self.positives[idx]

        if self.transform:
            positive = self.transform(positive)

        return anchor, positive


# Generic version used for the entire dataset (once ready)

class FiskeSet(Dataset):
    def __init__(self, anchors, positives, seed, transform=None):
        random.seed(seed)

        self.anchors = anchors
        self.positives = positives
        self.transform = transform

    def __len__(self):
        return len(self.positives)

    def __getitem__(self, idx):
        anchor = self.anchors[idx]
        positive = self.positives[idx]

        if self.transform:
            positive = self.transform(positive)

        return anchor, positive

class Discriminator(nn.Module):
    def __init__(self, channels_img, features_d):
        super(Discriminator, self).__init__()
        self.disc = nn.Sequential(
            # input: N x channels_img x 64 x 64
            nn.Conv2d(
                channels_img, features_d, kernel_size=4, stride=2, padding=1
            ),
            nn.LeakyReLU(0.2),
            # _block(in_channels, out_channels, kernel_size, stride, padding)
            self._block(features_d, features_d * 2, 4, 2, 1),
            self._block(features_d * 2, features_d * 4, 4, 2, 1),
            self._block(features_d * 4, features_d * 8, 4, 2, 1),
            # After all _block img output is 4x4 (Conv2d below makes into 1x1)
            nn.Conv2d(features_d * 8, 1, kernel_size=4, stride=2, padding=0),
        )

    def _block(self, in_channels, out_channels, kernel_size, stride, padding):
        return nn.Sequential(
            nn.Conv2d(
                in_channels,
                out_channels,
                kernel_size,
                stride,
                padding,
                bias=False,
            ),
            nn.InstanceNorm2d(out_channels, affine=True),
            nn.LeakyReLU(0.2),
        )

    def forward(self, x):
        return self.disc(x)


class Generator(nn.Module):
    def __init__(self, channels_noise, channels_img, features_g):
        super(Generator, self).__init__()
        self.net = nn.Sequential(
            # Input: N x channels_noise x 1 x 1
            self._block(channels_noise, features_g * 16, 4, 1, 0),  # img: 4x4
            self._block(features_g * 16, features_g * 8, 4, 2, 1),  # img: 8x8
            self._block(features_g * 8, features_g * 4, 4, 2, 1),  # img: 16x16
            self._block(features_g * 4, features_g * 2, 4, 2, 1),  # img: 32x32
            nn.ConvTranspose2d(
                features_g * 2, channels_img, kernel_size=4, stride=2, padding=1
            ),
            # Output: N x channels_img x 64 x 64
            nn.Tanh(),
        )

    def _block(self, in_channels, out_channels, kernel_size, stride, padding):
        return nn.Sequential(
            nn.ConvTranspose2d(
                in_channels,
                out_channels,
                kernel_size,
                stride,
                padding,
                bias=False,
            ),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(),
        )

    def forward(self, x):
        return self.net(x)


def initialize_weights(model):
    # Initializes weights according to the DCGAN paper
    for m in model.modules():
        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):
            nn.init.normal_(m.weight.data, 0.0, 0.02)

def images_to_vectors(images):
    return images.view(images.size(0), (4096*3))

def vectors_to_images(vectors):
    return vectors.view(vectors.size(0), 3, 64, 64)

def show_img(rgb_matrix):
  img = rgb_matrix.permute(1, 2, 0)
  img = img.cpu().detach().numpy()
  img = np.array(img)
  plt.imshow(img)
  plt.show()

def generate_genres_tensor(genres_vectors):
    """
    Takes a bunch of vectors (numpy arrays) of genre-names and creates one-hot vectors
    based on them. The resulting tensor can be concatenated to anchors using .cat.
    SHOULD BE WORKING, but maybe some quick testing is in order ;)
    """
    genres_master = ["Blues", "Classical", "Electronic", "Folk World & Country", "Funk / Soul", "Hip Hop", "Jazz",
                     "Latin",
                     "Pop", "Reggae", "Rock"]
    genres_tensor = []
    for idx, genres in enumerate(genres_vectors):
        list_vector = []
        if "Folk" in genres:
            genres = genres.replace("Folk, World,", "Folk World")
        genres = genres.split(", ")
        for i, g in enumerate(genres_master):
            if g in genres:
                list_vector.append(1)
            else:
                list_vector.append(0)
        genres_tensor.append(torch.tensor(list_vector))
    genres_tensor = torch.stack(tuple(genres_tensor))
    return genres_tensor


# One hot encoding for years.
def generate_years_tensor(years_vectors):
    years_master = list(range(100))

    years_tensor = []
    for idx, year in enumerate(years_vectors):
        list_vector = []
        for y in years_master:
            if (int(year[-2:]) == int(y)):
                list_vector.append(1)
            else:
                list_vector.append(0)
        years_tensor.append(torch.tensor(list_vector))
    years_tensor = torch.stack(tuple(years_tensor))
    return years_tensor


def data_normalization(data):
    minimum = np.amin(data)
    maximum = np.amax(data)
    for i in range(len(data)):
        data[i] = (data[i] - minimum) / (maximum - minimum)

    return torch.tensor(data)


def create_dataset(path, input_attributes, seed, amount=None, debug=False):
    h = h5py.File(path)

    svd_attributes = list(h["Single Value Data"].attrs["column_names"])
    # print(svd_attributes)
    # print(h["Metadata"].attrs["column_names"])
    md_attributes = list(h["Metadata"].attrs["column_names"])

    svd_idx_list = []
    tensor_lyf = []
    if debug:
        random.seed(seed)
        rands = random.sample(range(h["Single Value Data"].shape[0]), amount)
        rands.sort()
        images = h["Images"][rands]
        for att in input_attributes:
            if "Genres" == att:
                genres_vectors = h["Metadata"].asstr()[rands, md_attributes.index("Genres")]
                genres_tensor = generate_genres_tensor(genres_vectors)
                tensor_lyf.append(genres_tensor)
                # anchors = torch.cat((anchors, genres_tensor), dim=1)
            elif "Year" == att:
                years_vectors = h["Metadata"].asstr()[rands, md_attributes.index("Year")]
                years_tensor = generate_years_tensor(years_vectors)
                tensor_lyf.append(years_tensor)
                # anchors = torch.cat((anchors, years_tensor), dim=1)
            elif "_norm" in att:
                clean_att = att.replace("_norm", "")
                idx = svd_attributes.index(clean_att)
                att_vectors = h["Single Value Data"][rands, idx]
                att_tensor = data_normalization(att_vectors)
                att_tensor = att_tensor[:, None]
                tensor_lyf.append(att_tensor)
                # anchors = torch.cat((anchors, att_tensor), dim=1)
            else:
                svd_idx_list.append(svd_attributes.index(att))
        for svd in svd_idx_list:
            addition_tensor = h["Single Value Data"][rands, svd]
            addition_tensor = addition_tensor[:, None]
            tensor_lyf.append(torch.tensor(addition_tensor))
        anchors = torch.cat(tuple(tensor_lyf), dim=1)
        print("Anchors SHAPE:", anchors.shape)
        dataset = FiskeSet_test(anchors, images, seed, amount, transform)

    else:
        images = h["Images"]
        for att in input_attributes:
            if "Genres" == att:
                genres_vectors = h["Metadata"].asstr()[:, md_attributes.index("Genres")]
                genres_tensor = generate_genres_tensor(genres_vectors)
                tensor_lyf.append(genres_tensor)
            elif "Year" == att:
                years_vectors = h["Metadata"].asstr()[:, md_attributes.index("Year")]
                years_tensor = generate_years_tensor(years_vectors)
                tensor_lyf.append(years_tensor)
            elif "_norm" in att:
                clean_att = att.replace("_norm", "")
                idx = svd_attributes.index(clean_att)
                att_vectors = h["Single Value Data"][:, idx]
                att_tensor = data_normalization(att_vectors)
                att_tensor = att_tensor[:, None]
                tensor_lyf.append(att_tensor)
            else:
                svd_idx_list.append(svd_attributes.index(att))
        for svd in svd_idx_list:
            addition_tensor = h["Single Value Data"][:, svd]
            addition_tensor = addition_tensor[:, None]
            tensor_lyf.append(torch.tensor(addition_tensor))
        anchors = torch.cat(tuple(tensor_lyf), dim=1)
        print("Anchors SHAPE:", anchors.shape)

        dataset = FiskeSet(anchors, images, seed, transform)
        # print("Hello?", genres_tensor.shape, anchors.shape)

    return dataset

"""# Paths"""
#Put name here!
base_path = "/home/data_shares/fiskkagedata/"
checkpoint_path = rf"{base_path}/ML_models/checkpoints/"
train_path = rf"{base_path}dataset/Train.hdf5"
dev_path = rf"{base_path}dataset/dev.hdf5"

if __name__ == '__main__':
    """# Global settings"""
    batch_size = 128
    seed = 42
    epochs = 500

    input_attributes =  ["energy", "danceability", "speechiness", "acousticness", "instrumentalness",
     "liveness", "valence", "tempo_norm", "loudness_norm", "key_norm",
     "mode"]

    device = 'cuda' if torch.cuda.is_available() else 'cpu'

    print(device)

    """# Data loader"""
    print("Creating train set")
    train_set = create_dataset(train_path, input_attributes, seed)
    print("Creating data loader")
    trainloader = DataLoader(train_set, shuffle = True, num_workers=2, batch_size=batch_size)

    # Hyperparameters etc
    LEARNING_RATE = 5e-5
    BATCH_SIZE = 128
    IMAGE_SIZE = 64
    CHANNELS_IMG = 3
    Z_DIM = 11
    NUM_EPOCHS = 500
    FEATURES_CRITIC = 64
    FEATURES_GEN = 64
    CRITIC_ITERATIONS = 5
    WEIGHT_CLIP = 0.01

    transforms = transforms.Compose(
        [
            transforms.Resize(IMAGE_SIZE),
            transforms.ToTensor(),
            transforms.Normalize(
                [0.5 for _ in range(CHANNELS_IMG)], [0.5 for _ in range(CHANNELS_IMG)]
            ),
        ]
    )

    # initialize gen and disc/critic
    gen = Generator(Z_DIM, CHANNELS_IMG, FEATURES_GEN).to(device)
    critic = Discriminator(CHANNELS_IMG, FEATURES_CRITIC).to(device)
    initialize_weights(gen)
    initialize_weights(critic)

    # initializate optimizer
    opt_gen = optim.RMSprop(gen.parameters(), lr=LEARNING_RATE)
    opt_critic = optim.RMSprop(critic.parameters(), lr=LEARNING_RATE)

    # for tensorboard plotting
    fixed_noise = torch.randn(32, Z_DIM, 1, 1).to(device)

    step = 0

    gen.train()
    critic.train()

    enable_checkpoints = True
    print(f"With enable_checkpoints={enable_checkpoints}")

    if enable_checkpoints:
      time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
      folder_path = checkpoint_path + "/ALADDIN_SVF_WGAN_" + str(time)
      os.mkdir(folder_path)
      os.mkdir(folder_path + "/Generator")
      os.mkdir(folder_path + "/Discriminator")
      h = h5py.File(f"{folder_path}/GANImages.hdf5", "a")
      h.close()


      with open(folder_path + r"/model_settings.txt", "w") as current_settings:
        current_settings.write(f"ATTRIBUTES: {input_attributes} \nSEED: {seed} \nBATCH SIZE: {batch_size}")

      with open(folder_path + r"/Gnet_epoch_losses.csv", "w", encoding="UTF8", newline="") as epoch_losses:
        writer = csv.writer(epoch_losses, delimiter=";")
        writer.writerow(["EPOCH", "LOSS PER SAMPLE"])

      with open(folder_path + r"/Dnet_epoch_losses.csv", "w", encoding="UTF8", newline="") as epoch_losses:
        writer = csv.writer(epoch_losses, delimiter=";")
        writer.writerow(["EPOCH", "LOSS PER SAMPLE"])

      with open(folder_path + r"/Batch_losses.csv", "w", encoding="UTF8", newline="") as epoch_losses:
        writer = csv.writer(epoch_losses, delimiter=";")
        writer.writerow(["BATCH_IDX", "GNET_LOSS", "DNET_LOSS"])

    for epoch in range(NUM_EPOCHS):
        # Target labels not needed! <3 unsupervised
        for batch_idx, (data, real_cpu) in enumerate(trainloader):
            data = data.anchors().to(device)
            data = data[:, :, None, None]
            real_cpu = real_cpu.anchors().to(device)
            cur_batch_size = data.shape[0]

            # Train Critic: max E[critic(real)] - E[critic(fake)]
            for _ in range(CRITIC_ITERATIONS):
                fake = gen(data)
                critic_real = critic(real_cpu).reshape(-1)
                critic_fake = critic(fake).reshape(-1)
                loss_critic = -(torch.mean(critic_real) - torch.mean(critic_fake))
                critic.zero_grad()
                loss_critic.backward(retain_graph=True)
                opt_critic.step()

                # clip critic weights between -0.01, 0.01
                for p in critic.parameters():
                    p.data.clamp_(-WEIGHT_CLIP, WEIGHT_CLIP)

            # Train Generator: max E[critic(gen_fake)] <-> min -E[critic(gen_fake)]
            gen_fake = critic(fake).reshape(-1)
            loss_gen = -torch.mean(gen_fake)
            gen.zero_grad()
            loss_gen.backward()
            opt_gen.step()

            # Print losses occasionally and print to tensorboard
            if batch_idx % 100 == 0 and batch_idx > 0:
                gen.eval()
                critic.eval()
                print(
                    f"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(trainloader)} \
                      Loss D: {loss_critic:.4f}, loss G: {loss_gen:.4f}"
                )
                with open(folder_path + r"/Batch_losses.csv", "a", encoding="UTF8", newline="") as epoch_losses:
                  writer = csv.writer(epoch_losses, delimiter=";")
                  writer.writerow([batch_idx, loss_gen.item(), loss_critic.item()])
                step += 1
                gen.train()
                critic.train()

        if enable_checkpoints:
            torch.save(gen.state_dict(), f"{folder_path}/Generator/Generator_epoch_{epoch}")
            torch.save(critic.state_dict(), f"{folder_path}/Discriminator/Discriminator_epoch_{epoch}")
            sample_loader = DataLoader(train_set, 64, False, num_workers=2)
            ancs, poss = next(iter(sample_loader))
            ancs = ancs.float().to(device)
            ancs = ancs[:, :, None, None]
            fake = Gnet(ancs).detach().cpu()
            fake = vectors_to_images(fake)
            fake = fake[None, :, :, :, :]
            h = h5py.File(f"{folder_path}/GANImages.hdf5", "a")
            if "RGBMats" not in h:
                h.create_dataset("RGBMats", data=fake, shape=(1, 64, 3, 64, 64), maxshape=(None, 64, 3, 64, 64))
            else:
                past_size = h["RGBMats"].shape[0]
                h["RGBMats"].resize(past_size + 1, 0)
                h["RGBMats"][past_size] = fake
            with open(folder_path + r"/Gnet_epoch_losses.csv", "a", encoding="UTF8", newline="") as epoch_losses:
              writer = csv.writer(epoch_losses, delimiter=";")
              writer.writerow([epoch, loss_gen.item()])
            with open(folder_path + r"/Dnet_epoch_losses.csv", "a", encoding="UTF8", newline="") as epoch_losses:
              writer = csv.writer(epoch_losses, delimiter=";")
              writer.writerow([epoch, loss_critic.item()])
            h.close()
