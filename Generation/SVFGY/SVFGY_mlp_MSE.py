# -*- coding: utf-8 -*-
"""GAN(G).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ixFBKXfum2k6uieCbeaMEx74pgRyGO4N

# Mount drive
"""

"""# Imports"""
import torch
from torch.utils.data import Dataset, DataLoader
from torch import nn, optim
import torch.nn.functional as F
from torch.autograd.variable import Variable
from torchvision import transforms
import random
import numpy as np
import h5py
import matplotlib.pyplot as plt
from datetime import datetime
import os
import sys
import csv

csv.field_size_limit(sys.maxsize)

transform = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

"""# Dataset"""


# Current version used for testing the set up
class FiskeSet_test(Dataset):
    def __init__(self, anchors, positives, seed, amount, transform=None):
        random.seed(seed)
        if amount <= 1:
            raise Exception("Amount of samples must be greater than 1 or negatives cannot be fetched.")

        self.anchors = anchors
        self.positives = positives
        self.transform = transform
        self.amount = amount

    def __len__(self):
        return self.amount

    def __getitem__(self, idx):
        anchor = self.anchors[idx]
        positive = self.positives[idx]

        if self.transform:
            positive = self.transform(positive)

        return anchor, positive


# Generic version used for the entire dataset (once ready)

class FiskeSet(Dataset):
    def __init__(self, anchors, positives, seed, transform=None):
        random.seed(seed)

        self.anchors = anchors
        self.positives = positives
        self.transform = transform

    def __len__(self):
        return len(self.positives)

    def __getitem__(self, idx):
        anchor = self.anchors[idx]
        positive = self.positives[idx]

        if self.transform:
            positive = self.transform(positive)

        return anchor, positive


class GeneratorNet(torch.nn.Module):
    def __init__(self, in_dim, out_dim):
        super(GeneratorNet, self).__init__()
        n_features = in_dim
        n_out = out_dim

        self.hidden0 = nn.Sequential(
            nn.Linear(n_features, 256),
            nn.LeakyReLU(0.2)
        )

        self.hidden1 = nn.Sequential(
            nn.Linear(256, 512),
            nn.LeakyReLU(0.2)
        )

        self.hidden2 = nn.Sequential(
            nn.Linear(512, 1024),
            nn.LeakyReLU(0.2)
        )

        self.out = nn.Sequential(
            nn.Linear(1024, n_out),
            nn.Tanh()
        )

    def forward(self, x):
        x = self.hidden0(x)
        x = self.hidden1(x)
        x = self.hidden2(x)
        x = self.out(x)
        return x


class MLP(nn.Module):
    def __init__(self, in_dim, out_dim):
        super().__init__()
        self.fc1 = nn.Linear(in_dim, 32)
        self.fc2 = nn.Linear(32, 64)
        self.fc3 = nn.Linear(64, out_dim)

    def forward(self, x):
        x = self.fc1(x)
        x = F.leaky_relu(x)
        x = self.fc2(x)
        x = F.leaky_relu(x)
        x = self.fc3(x)
        x = torch.tanh(x)

        return x


def images_to_vectors(images):
    return images.view(images.size(0), (4096 * 3))


def vectors_to_images(vectors):
    return vectors.view(vectors.size(0), 3, 64, 64)


def show_img(rgb_matrix):
    img = rgb_matrix.permute(1, 2, 0)
    img = img.cpu().detach().numpy()
    img = np.array(img)
    plt.imshow(img)
    plt.show()


def generate_genres_tensor(genres_vectors):
    """
    Takes a bunch of vectors (numpy arrays) of genre-names and creates one-hot vectors
    based on them. The resulting tensor can be concatenated to anchors using .cat.
    SHOULD BE WORKING, but maybe some quick testing is in order ;)
    """
    genres_master = ["Blues", "Classical", "Electronic", "Folk World & Country", "Funk / Soul", "Hip Hop", "Jazz",
                     "Latin",
                     "Pop", "Reggae", "Rock"]
    genres_tensor = []
    for idx, genres in enumerate(genres_vectors):
        list_vector = []
        if "Folk" in genres:
            genres = genres.replace("Folk, World,", "Folk World")
        genres = genres.split(", ")
        for i, g in enumerate(genres_master):
            if g in genres:
                list_vector.append(1)
            else:
                list_vector.append(0)
        genres_tensor.append(torch.tensor(list_vector))
    genres_tensor = torch.stack(tuple(genres_tensor))
    return genres_tensor


# One hot encoding for years.
def generate_years_tensor(years_vectors):
    years_master = list(range(100))

    years_tensor = []
    for idx, year in enumerate(years_vectors):
        list_vector = []
        for y in years_master:
            if (int(year[-2:]) == int(y)):
                list_vector.append(1)
            else:
                list_vector.append(0)
        years_tensor.append(torch.tensor(list_vector))
    years_tensor = torch.stack(tuple(years_tensor))
    return years_tensor


def data_normalization(data):
    minimum = np.amin(data)
    maximum = np.amax(data)
    for i in range(len(data)):
        data[i] = (data[i] - minimum) / (maximum - minimum)

    return torch.tensor(data)


def create_dataset(path, input_attributes, seed, amount=None, debug=False):
    h = h5py.File(path)

    svd_attributes = list(h["Single Value Data"].attrs["column_names"])
    # print(svd_attributes)
    # print(h["Metadata"].attrs["column_names"])
    md_attributes = list(h["Metadata"].attrs["column_names"])

    svd_idx_list = []
    tensor_lyf = []
    if debug:
        random.seed(seed)
        rands = random.sample(range(h["Single Value Data"].shape[0]), amount)
        rands.sort()
        images = h["Images"][rands]
        for att in input_attributes:
            if "Genres" == att:
                genres_vectors = h["Metadata"].asstr()[rands, md_attributes.index("Genres")]
                genres_tensor = generate_genres_tensor(genres_vectors)
                tensor_lyf.append(genres_tensor)
                # anchors = torch.cat((anchors, genres_tensor), dim=1)
            elif "Year" == att:
                years_vectors = h["Metadata"].asstr()[rands, md_attributes.index("Year")]
                years_tensor = generate_years_tensor(years_vectors)
                tensor_lyf.append(years_tensor)
                # anchors = torch.cat((anchors, years_tensor), dim=1)
            elif "_norm" in att:
                clean_att = att.replace("_norm", "")
                idx = svd_attributes.index(clean_att)
                att_vectors = h["Single Value Data"][rands, idx]
                att_tensor = data_normalization(att_vectors)
                att_tensor = att_tensor[:, None]
                tensor_lyf.append(att_tensor)
                # anchors = torch.cat((anchors, att_tensor), dim=1)
            else:
                svd_idx_list.append(svd_attributes.index(att))
        for svd in svd_idx_list:
            addition_tensor = h["Single Value Data"][rands, svd]
            addition_tensor = addition_tensor[:, None]
            tensor_lyf.append(torch.tensor(addition_tensor))
        anchors = torch.cat(tuple(tensor_lyf), dim=1)
        print("Anchors SHAPE:", anchors.shape)
        dataset = FiskeSet_test(anchors, images, seed, amount, transform)

    else:
        images = h["Images"]
        for att in input_attributes:
            if "Genres" == att:
                genres_vectors = h["Metadata"].asstr()[:, md_attributes.index("Genres")]
                genres_tensor = generate_genres_tensor(genres_vectors)
                tensor_lyf.append(genres_tensor)
            elif "Year" == att:
                years_vectors = h["Metadata"].asstr()[:, md_attributes.index("Year")]
                years_tensor = generate_years_tensor(years_vectors)
                tensor_lyf.append(years_tensor)
            elif "_norm" in att:
                clean_att = att.replace("_norm", "")
                idx = svd_attributes.index(clean_att)
                att_vectors = h["Single Value Data"][:, idx]
                att_tensor = data_normalization(att_vectors)
                att_tensor = att_tensor[:, None]
                tensor_lyf.append(att_tensor)
            else:
                svd_idx_list.append(svd_attributes.index(att))
        for svd in svd_idx_list:
            addition_tensor = h["Single Value Data"][:, svd]
            addition_tensor = addition_tensor[:, None]
            tensor_lyf.append(torch.tensor(addition_tensor))
        anchors = torch.cat(tuple(tensor_lyf), dim=1)
        print("Anchors SHAPE:", anchors.shape)

        dataset = FiskeSet(anchors, images, seed, transform)
        # print("Hello?", genres_tensor.shape, anchors.shape)

    return dataset


"""# Paths"""
# Put name here!
base_path = "/home/data_shares/fiskkagedata/"
checkpoint_path = rf"{base_path}ML_models/checkpoints"
train_path = rf"{base_path}dataset/Train.hdf5"
dev_path = rf"{base_path}dataset/dev.hdf5"

if __name__ == '__main__':
    """# Global settings"""
    batch_size = 16
    seed = 42
    epochs = 500

    input_attributes = ["energy", "danceability", "speechiness", "acousticness", "instrumentalness",
                        "liveness", "valence", "Year", "Genres", "tempo_norm", "loudness_norm", "key_norm",
                        "mode"]

    device = 'cuda' if torch.cuda.is_available() else 'cpu'

    print(device)

    """# Data loader"""
    print("Creating train set")
    train_set = create_dataset(train_path, input_attributes, seed)
    print("Creating data loader")
    trainloader = DataLoader(train_set, shuffle=True, num_workers=2, batch_size=batch_size)

    # Version 2
    # Generated images are greyscale, but true images  are RGB, requires n_out=4096
    print("Set up mlp")
    mlp = MLP(122, 128).to(device)
    mlp.load_state_dict(torch.load(f"{base_path}jobs/scripts/generation/SVFGY/MLP", map_location=torch.device(device)))
    print("Set up generator")

    generator = GeneratorNet(128, 4096 * 3).to(device)
    params = list(generator.parameters())
    params.extend(mlp.parameters())
    g_optimizer = optim.Adam(params, lr=0.0002)
    criterion = nn.MSELoss()

    enable_checkpoints = True

    print(f"With enable_checkpoints={enable_checkpoints}")
    if enable_checkpoints:
        time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        folder_path = checkpoint_path + "/SVFGY_MSE_" + str(time)
        os.mkdir(folder_path)
        os.mkdir(folder_path + "/gan")
        os.mkdir(folder_path + "/mlp")
        h = h5py.File(f"{folder_path}/GANImages.hdf5", "a")
        h.close()

        with open(folder_path + r"/model_settings.txt", "w") as current_settings:
            current_settings.write(f"ATTRIBUTES: {input_attributes} \nSEED: {seed} \nBATCH SIZE: {batch_size}")

        with open(folder_path + r"/epoch_losses.csv", "w", encoding="UTF8", newline="") as epoch_losses:
            writer = csv.writer(epoch_losses, delimiter=";")
            writer.writerow(["EPOCH", "LOSS PER SAMPLE"])

    for epoch in range(epochs):
        running_loss = 0.0

        for i, data in enumerate(trainloader):
            anchors, positives = data

            anchors = anchors.to(device)
            anchors = anchors.float()

            positives = positives.to(device)
            positives = positives.float()
            # print(positives.shape)
            positives = torch.flatten(positives, start_dim=2)
            # print(positives.shape)

            g_optimizer.zero_grad()

            anchors = mlp(anchors)
            anchors = generator(anchors)

            anchors = torch.reshape(anchors, (positives.shape[0], 3, 4096))

            # Positives prob has wrong shape (might need to be pancake'ed 🥞)
            loss = criterion(anchors, positives)
            loss.backward()
            g_optimizer.step()

            running_loss += loss.item()

        print(running_loss / len(train_set))
        if enable_checkpoints:
            torch.save(generator.state_dict(), f"{folder_path}/gan/GAN_epoch_{epoch}")
            torch.save(mlp.state_dict(), f"{folder_path}/mlp/MLP_epoch_{epoch}")
            sample_loader = DataLoader(train_set, 64, False, num_workers=2)
            ancs, poss = next(iter(sample_loader))
            ancs = ancs.float().to(device)
            ancs = mlp(ancs)
            fake = generator(ancs).detach().cpu()
            fake = vectors_to_images(fake)
            fake = fake[None, :, :, :, :]
            h = h5py.File(f"{folder_path}/GANImages.hdf5", "a")
            if "RGBMats" not in h:
                h.create_dataset("RGBMats", data=fake, shape=(1, 64, 3, 64, 64), maxshape=(None, 64, 3, 64, 64))
            else:
                past_size = h["RGBMats"].shape[0]
                h["RGBMats"].resize(past_size + 1, 0)
                h["RGBMats"][past_size] = fake
            with open(folder_path + r"/epoch_losses.csv", "a", encoding="UTF8", newline="") as epoch_losses:
                writer = csv.writer(epoch_losses, delimiter=";")
                writer.writerow([epoch, running_loss / (len(train_set))])
            h.close()
    # devloader = DataLoader(dev_set, batch_size=1, shuffle=False, num_workers=2)
