{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wig3P2tUSYPy"
      },
      "source": [
        "# Mount Google Drive\n",
        "For easy access to datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woCAiXwCO8UN",
        "outputId": "ca2d303a-7fd0-4a38-ccc1-d6aac1f59643"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oP2r8E_xSfju"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBTmatDSV7j5",
        "outputId": "e448ff41-6861-4bc3-bf92-07f9dc16aa11"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "131072"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, random_split, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import h5py\n",
        "import numpy as np\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "from datetime import datetime\n",
        "import csv\n",
        "import sys\n",
        "import math\n",
        "csv.field_size_limit(sys.maxsize)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwPCYCT3emx9"
      },
      "source": [
        "# Paths\n",
        "Specify if Christian or Philip here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-paJ85xerTD"
      },
      "outputs": [],
      "source": [
        "#Put name here!\n",
        "name = \"christian\"\n",
        "\n",
        "if name.lower() == \"christian\":\n",
        "  checkpoint_path = r\"/content/drive/MyDrive/ML models/Checkpoints/IRM\"\n",
        "  master_path = r\"/content/drive/MyDrive/Data/For Machines.hdf5\"\n",
        "  minmax_path = r\"/content/drive/MyDrive/Data/minmax.hdf5\"\n",
        "  train_path = r\"/content/drive/MyDrive/Data/Train.hdf5\"\n",
        "  dev_path = r\"/content/drive/MyDrive/Data/Dev.hdf5\"\n",
        "  csv_path = r\"/content/drive/MyDrive/Data/CSV_Data\"\n",
        "elif name.lower() == \"philip\":\n",
        "  checkpoint_path = r\"/content/drive/MyDrive/ITU/Software Design - Kandidat/Master Thesis/ML models/Checkpoints/IRM\"\n",
        "  train_path = r\"/content/drive/MyDrive/ITU/Software Design - Kandidat/Master Thesis/Data/Train.hdf5\"\n",
        "  master_path = r\"/content/drive/MyDrive/ITU/Software Design - Kandidat/Master Thesis/Data/For Machines.hdf5\"\n",
        "  minmax_path = r\"/content/drive/MyDrive/ITU/Software Design - Kandidat/Master Thesis/Data/minmax.hdf5\"\n",
        "  dev_path = r\"/content/drive/MyDrive/ITU/Software Design - Kandidat/Master Thesis/Data/Dev.hdf5\"\n",
        "  csv_path = r\"/content/drive/MyDrive/ITU/Software Design - Kandidat/Master Thesis/Data/CSV_Data\"\n",
        "else:\n",
        "  raise Exception(\"Invalid name for path - use 'christian' or 'philip'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tTs2-3cShhS"
      },
      "source": [
        "# Dataset Class\n",
        "Note, this is slightly different from the tutorial that this implementation is based on as our dataset is in the *HDF5*-format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Fb4lpUCfPQf"
      },
      "outputs": [],
      "source": [
        "# Current version used for testing the set up\n",
        "\n",
        "class FiskeSet_test(Dataset):\n",
        "  def __init__(self, anchors, positives, seed, amount, transform=None, version=\"vanilla\"):\n",
        "    random.seed(seed)\n",
        "    if amount <=1:\n",
        "      raise Exception(\"Amount of samples must be greater than 1 or negatives cannot be fetched.\")\n",
        "\n",
        "\n",
        "    self.anchors = anchors\n",
        "    self.positives = positives\n",
        "    self.transform = transform\n",
        "    self.amount = amount\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.amount\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    anchor = self.anchors[idx]\n",
        "    positive = self.positives[idx]\n",
        "\n",
        "    negative = self.anchors[random.choice(range(self.amount))]\n",
        "    while torch.all(torch.eq(anchor, negative)):\n",
        "      negative = self.anchors[random.choice(range(self.amount))]\n",
        "\n",
        "    if self.transform:\n",
        "      if version != \"vanilla\":\n",
        "        positive = Image.fromarray(positive)\n",
        "      positive = self.transform(positive)\n",
        "\n",
        "    return anchor, positive, negative"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYrPz1O8qMvT"
      },
      "outputs": [],
      "source": [
        "# Generic version used for the entire dataset (once ready)\n",
        "\n",
        "class FiskeSet(Dataset):\n",
        "  def __init__(self, anchors, positives, seed, transform=None, version = \"vanilla\"):\n",
        "    random.seed(seed)\n",
        "    \n",
        "    self.anchors = anchors\n",
        "    self.positives = positives\n",
        "    self.transform = transform\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.positives)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    anchor = self.anchors[idx]\n",
        "    positive = self.positives[idx]\n",
        "\n",
        "    negative = random.choice(self.anchors)\n",
        "    while torch.all(torch.eq(anchor, negative)):\n",
        "      negative = random.choice(self.anchors)\n",
        "\n",
        "    if self.transform:\n",
        "      if version != \"vanilla\":\n",
        "        positive = Image.fromarray(positive)\n",
        "      positive = self.transform(positive)\n",
        "\n",
        "    return anchor, positive, negative"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5NJSe5fStsY"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nAmByBwFCJh"
      },
      "outputs": [],
      "source": [
        "#Images need to be transformed in accordance with the specifications of the version\n",
        "\n",
        "version = \"vanilla\"\n",
        "\n",
        "if version == \"resnet\":\n",
        "  transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "elif version == \"vanilla\":\n",
        "  transform = transforms.Compose(\n",
        "      [transforms.ToTensor(),\n",
        "      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "else:\n",
        "  raise Exception(\"Please input a valid cnn-model\")\n",
        "\n",
        "def seq_data_normalization(data):\n",
        "  h = h5py.File(minmax_path, \"r\")\n",
        "  mins = h[\"Timbres\"][0]\n",
        "  maxs = h[\"Timbres\"][1]\n",
        "  for i in range(data.shape[2]):\n",
        "    lfunc = lambda e: (e-mins[i])/(maxs[i]-mins[i])\n",
        "    data[:, :, i] = lfunc(data[:, :, i])\n",
        "  \n",
        "  return data\n",
        "\n",
        "\n",
        "def create_sequential_dataset_advanced_padding(path, input_attributes, seed, length=1024, amount = None, debug = False, version=\"vanilla\", normalized=False):\n",
        "  \"\"\"\n",
        "  Multiple Sequential Data attributes will make this break (overwrites anchors each time)\n",
        "  \"\"\"\n",
        "  h = h5py.File(path, \"r\")\n",
        "  legal = all([att in h.keys() for att in input_attributes])\n",
        "  if legal:\n",
        "    if debug:\n",
        "      random.seed(seed)\n",
        "      rands = random.sample(range(h[\"Single Value Data\"].shape[0]), amount)\n",
        "      rands.sort()\n",
        "      images = h[\"Images\"][rands]\n",
        "      for att in input_attributes:\n",
        "        anchors = torch.tensor(h[att][rands, :length, :])\n",
        "        if normalized:\n",
        "          anchors = seq_data_normalization(anchors)\n",
        "        anchors2 = torch.zeros(anchors.shape[0], 1024, 12)\n",
        "        for idx, anchor in enumerate(anchors):\n",
        "          #shape = (1024, 12)\n",
        "          infs = (anchor == math.inf).nonzero(as_tuple=True)[0]\n",
        "          if len(infs) > 0:\n",
        "            base_anchor = anchor[:infs[0], :]\n",
        "            #shape = (L, 12)\n",
        "            L = base_anchor.shape[0]\n",
        "            x = (length-L) // 2\n",
        "            if (length-L) % 2 == 0:\n",
        "              anchor = F.pad(base_anchor, (0, 0, x, x))\n",
        "            else:\n",
        "              base_anchor = torch.cat((base_anchor, torch.tensor([[0]*12])))\n",
        "              anchor = F.pad(base_anchor, (0, 0, x, x))\n",
        "            anchor[anchor == math.inf] = 0\n",
        "            anchors2[idx] = anchor\n",
        "      anchors2 = anchors2.permute(0, 2, 1)\n",
        "      dataset = FiskeSet_test(anchors2, images, seed, amount, transform, version)\n",
        "    else:\n",
        "      #Is missing      \n",
        "      images = h[\"Images\"]\n",
        "      for att in input_attributes:\n",
        "        anchors = torch.tensor(h[att][:, :length, :])\n",
        "        if normalized:\n",
        "          anchors = seq_data_normalization(anchors)\n",
        "        anchors2 = torch.zeros(anchors.shape[0], 1024, 12)    \n",
        "        for idx, anchor in enumerate(anchors):\n",
        "          #shape = (1024, 12)\n",
        "          infs = (anchor == math.inf).nonzero(as_tuple=True)[0]\n",
        "          if len(infs) > 0:\n",
        "            base_anchor = anchor[:infs[0], :]\n",
        "            #shape = (L, 12)\n",
        "            L = base_anchor.shape[0]\n",
        "            x = (length-L) // 2\n",
        "            if (length-L) % 2 == 0:\n",
        "              anchor = F.pad(base_anchor, (0, 0, x, x))\n",
        "            else:\n",
        "              base_anchor = torch.cat((base_anchor, torch.tensor([[0]*12])))\n",
        "              anchor = F.pad(base_anchor, (0, 0, x, x))\n",
        "            anchor[anchor == math.inf] = 0\n",
        "            anchors2[idx] = anchor    \n",
        "      anchors2 = anchors2.permute(0, 2, 1)\n",
        "      dataset = FiskeSet(anchors2, images, seed, transform, version)\n",
        "    \n",
        "    return dataset\n",
        "  else:\n",
        "    raise Exception(\"You make crai with illegal attributes :(\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAThTrWCyfxz"
      },
      "source": [
        "# Image conversion setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUNRjqPhynrK"
      },
      "outputs": [],
      "source": [
        "def show_img(rgb_matrix):\n",
        "  img = rgb_matrix.permute(1, 2, 0)\n",
        "  img = np.array(img)\n",
        "  plt.imshow(img)\n",
        "\n",
        "def show_x_images(imgs):\n",
        "  fig = plt.figure(figsize=(50, 30))\n",
        "\n",
        "  x = len(imgs)\n",
        "  # setting values to rows and column variables\n",
        "  if x % 2 == 0:\n",
        "    rows = x/2\n",
        "    columns = x/2\n",
        "  else:\n",
        "    rows = (x+1)/2\n",
        "    columns = (x+1)/2\n",
        "\n",
        "  for i in range(1, x+1):\n",
        "    # Adds a subplot at the 1st position\n",
        "    fig.add_subplot(rows, columns, i)\n",
        "\n",
        "    # showing image\n",
        "    show_img(imgs[i-1])\n",
        "    plt.axis('off')\n",
        "    plt.title(i)\n",
        "\n",
        "def show_images_advanced(img_dict, image_path, save = False):\n",
        "  fig = plt.figure(figsize=(20, 20))\n",
        "  plt.tight_layout()\n",
        "  x = len(img_dict)\n",
        "  postfix = str(x) + \"_images_\" + datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "  if x % 2 == 0:\n",
        "    rows = x//2\n",
        "    columns = x//2\n",
        "  else:\n",
        "    rows = (x+1)//2\n",
        "    columns = rows\n",
        "\n",
        "  print(rows)\n",
        "  print(columns)\n",
        " \n",
        "  idx = 0\n",
        "  for key, value in img_dict.items():\n",
        "    if key == \"Anchor\":\n",
        "      plt.subplot2grid((rows, columns), (0, columns//2-1), rowspan=2, colspan=2)\n",
        "      show_img(value)\n",
        "      plt.axis('off')\n",
        "      idx += columns*2\n",
        "\n",
        "    else:\n",
        "      plt.subplot2grid((rows, columns), (idx//rows, idx%columns))\n",
        "      show_img(value)\n",
        "      plt.axis('off')\n",
        "      idx += 1\n",
        "    plt.title(key)\n",
        "\n",
        "  if save:\n",
        "    plt.savefig(f\"{image_path}/{postfix}.pdf\", dpi=300, bbox_inches=\"tight\")\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPl7rVdFa1S_"
      },
      "source": [
        "# Training initialization\n",
        "Options are specified here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "BARU4KFZa7rB",
        "outputId": "03be6d1a-3985-4b26-d65a-a7336b4858a2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "input_attributes = [\"Timbres\"]\n",
        "seed = 42\n",
        "batch_size = 16\n",
        "\n",
        "amount = 10_000\n",
        "\n",
        "train_set = create_sequential_dataset_advanced_padding(train_path, input_attributes, seed=42, length=1024, amount=amount, debug=True, normalized=True)\n",
        "show_img(train_set[0][1])\n",
        "test_sample = train_set[0][0]\n",
        "\n",
        "#dev_set = create_dataset(dev_path, input_attributes)\n",
        "#test_set = create_dataset(test_path, input_attributes)\n",
        "amount = len(train_set)\n",
        "\n",
        "\n",
        "trainloader = DataLoader(train_set, shuffle = True, num_workers = 2, batch_size=batch_size)\n",
        "#devloader = DataLoader(dev_set, shuffle = True, num_workers = 2, batch_size=batch_size)\n",
        "#testloader = DataLoader(test_set, shuffle = True, num_workers = 2, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "co-q_h3yS6Oj"
      },
      "source": [
        "# Set Device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOtZpR1Uyp33",
        "outputId": "e997936a-90a7-4a82-857f-984707addccf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlPKYVIyS8Kc"
      },
      "source": [
        "# Image CNN class\n",
        "Output mapped between -1 to 1 with tanh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqsgx982mHdF"
      },
      "outputs": [],
      "source": [
        "class IMG_CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(3,6,5)\n",
        "    self.pool = nn.MaxPool2d(2,2)\n",
        "    self.conv2 = nn.Conv2d(6,16,5)\n",
        "    self.fc1 = nn.Linear(2704, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 128)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.leaky_relu(self.conv1(x))\n",
        "    x = self.pool(x)\n",
        "    x = F.leaky_relu(self.conv2(x))\n",
        "    x = self.pool(x)\n",
        "    x = torch.flatten(x,1)\n",
        "    x = F.leaky_relu(self.fc1(x))\n",
        "    x = F.leaky_relu(self.fc2(x)) \n",
        "    x = torch.tanh(self.fc3(x))\n",
        "\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGNoUnVga5hc"
      },
      "source": [
        "# Deep Image CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXEeSN7ya5HE"
      },
      "outputs": [],
      "source": [
        "class Deep_IMG_CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(3,6,5)\n",
        "    self.pool = nn.MaxPool2d(2,2)\n",
        "    self.conv2 = nn.Conv2d(6,16,5)\n",
        "    self.fc1 = nn.Linear(2704, 128)\n",
        "    self.fc2 = nn.Linear(128, 128)\n",
        "    self.fc3 = nn.Linear(128, 128)\n",
        "    self.fc4 = nn.Linear(128, 128)\n",
        "    self.fc5 = nn.Linear(128, 128)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    x = self.pool(F.leaky_relu(self.conv1(x)))\n",
        "    x = self.pool(F.leaky_relu(self.conv2(x)))\n",
        "    x = torch.flatten(x,1)\n",
        "    x = F.leaky_relu(self.fc1(x))\n",
        "    x = F.leaky_relu(self.fc2(x))\n",
        "    x = F.leaky_relu(self.fc3(x))\n",
        "    x = F.leaky_relu(self.fc4(x)) \n",
        "    x = torch.tanh(self.fc5(x))\n",
        "\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxglhCHX6Ymb"
      },
      "source": [
        "# Sequential Data CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0t20Q_B6b4V"
      },
      "outputs": [],
      "source": [
        "class SEQ_CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.dropout = nn.Dropout(p=0.2)\n",
        "    self.print = False\n",
        "\n",
        "  def forward(self, x):\n",
        "    if self.print:\n",
        "      print(\"RAW\")\n",
        "      print(x.shape)\n",
        "      x1 = F.leaky_relu(self.conv1(x))\n",
        "      print(\"First\")\n",
        "      print(x1.shape)\n",
        "      x1 = F.max_pool1d(x1, kernel_size=x1.size(2)).squeeze(2)\n",
        "      print(\"First pool\")\n",
        "      print(x1.shape)\n",
        "      x2 = F.leaky_relu(self.conv2(x))\n",
        "      print(\"Second conv\")\n",
        "      print(x2.shape)\n",
        "      x2 = F.max_pool1d(x2, x2.size(2)).squeeze(2)\n",
        "      print(\"Second pool\")\n",
        "      print(x2.shape)\n",
        "      x3 = F.leaky_relu(self.conv3(x))\n",
        "      print(\"Third conv\")\n",
        "      print(x3.shape)\n",
        "      x3 = F.max_pool1d(x3, x3.size(2)).squeeze(2)\n",
        "      print(\"Third pool\")\n",
        "      print(x3.shape)\n",
        "\n",
        "      out = torch.cat((x1, x2, x3), dim=1)\n",
        "      out = self.fc1(self.dropout(out))\n",
        "      out = torch.tanh(out)\n",
        "    else:\n",
        "      x1 = F.leaky_relu(self.conv1(x))\n",
        "      x1 = F.max_pool1d(x1, kernel_size=x1.size(2)).squeeze(2)\n",
        "\n",
        "      x2 = F.leaky_relu(self.conv2(x))\n",
        "      x2 = F.max_pool1d(x2, x2.size(2)).squeeze(2)\n",
        "\n",
        "      x3 = F.leaky_relu(self.conv3(x))\n",
        "      x3 = F.max_pool1d(x3, x3.size(2)).squeeze(2)\n",
        "      out = torch.cat((x1, x2, x3), dim=1)\n",
        "      out = self.fc1(self.dropout(out))\n",
        "      out = torch.tanh(out)\n",
        "\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZSVDHtGak89"
      },
      "source": [
        "# Deep Sequential Data CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C66TeceCarcZ"
      },
      "outputs": [],
      "source": [
        "class Deep_SEQ_CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv1d(12, 8, 6)\n",
        "    self.conv2 = nn.Conv1d(12, 8, 12)\n",
        "    self.conv3 = nn.Conv1d(12, 8, 24)\n",
        "    self.fc1 = nn.Linear(24, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 128)\n",
        "    self.dropout = nn.Dropout(p=0.2)\n",
        "    self.print = False\n",
        "\n",
        "  def forward(self, x):\n",
        "    if self.print:\n",
        "      print(\"RAW\")\n",
        "      print(x.shape)\n",
        "      x1 = F.leaky_relu(self.conv1(x))\n",
        "      print(\"First\")\n",
        "      print(x1.shape)\n",
        "      x1 = F.max_pool1d(x1, kernel_size=x1.size(2)).squeeze(2)\n",
        "      print(\"First pool\")\n",
        "      print(x1.shape)\n",
        "      x2 = F.leaky_relu(self.conv2(x))\n",
        "      print(\"Second conv\")\n",
        "      print(x2.shape)\n",
        "      x2 = F.max_pool1d(x2, x2.size(2)).squeeze(2)\n",
        "      print(\"Second pool\")\n",
        "      print(x2.shape)\n",
        "      x3 = F.leaky_relu(self.conv3(x))\n",
        "      print(\"Third conv\")\n",
        "      print(x3.shape)\n",
        "      x3 = F.max_pool1d(x3, x3.size(2)).squeeze(2)\n",
        "      print(\"Third pool\")\n",
        "      print(x3.shape)\n",
        "\n",
        "      out = torch.cat((x1, x2, x3), dim=1)\n",
        "      out = self.fc1(self.dropout(out))\n",
        "      out = self.fc2(self.dropout(out))\n",
        "      out = self.fc3(self.dropout(out))\n",
        "      out = torch.tanh(out)\n",
        "    else:\n",
        "      x1 = F.leaky_relu(self.conv1(x))\n",
        "      x1 = F.max_pool1d(x1, kernel_size=x1.size(2)).squeeze(2)\n",
        "\n",
        "      x2 = F.leaky_relu(self.conv2(x))\n",
        "      x2 = F.max_pool1d(x2, x2.size(2)).squeeze(2)\n",
        "\n",
        "      x3 = F.leaky_relu(self.conv3(x))\n",
        "      x3 = F.max_pool1d(x3, x3.size(2)).squeeze(2)\n",
        "      out = torch.cat((x1, x2, x3), dim=1)\n",
        "      out = self.fc1(self.dropout(out))\n",
        "      out = self.fc2(self.dropout(out))\n",
        "      out = self.fc3(self.dropout(out))\n",
        "      out = torch.tanh(out)\n",
        "\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RY2uLI4TdCs"
      },
      "source": [
        "# Loss and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aw8O0kmSndj2"
      },
      "outputs": [],
      "source": [
        "img_cnn = Deep_IMG_CNN().to(device)\n",
        "seq_cnn = Deep_SEQ_CNN().to(device)\n",
        "\n",
        "criterion = nn.TripletMarginLoss()\n",
        "params = list(img_cnn.parameters())\n",
        "params.extend(seq_cnn.parameters())\n",
        "optimizer = optim.Adam(params, lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCrgc3XGTh_E"
      },
      "source": [
        "# Training Routine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SE21tU8Wn35z"
      },
      "outputs": [],
      "source": [
        "img_cnn.train()\n",
        "seq_cnn.train()\n",
        "\n",
        "losses = []\n",
        "epochs = 40\n",
        "\n",
        "#Change to save checkpoints\n",
        "enable_checkpoints = True\n",
        "\n",
        "if enable_checkpoints:\n",
        "  time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "  folder_path = checkpoint_path + \"/\" + str(time)+ \"_SEQ_MODEL_12FOR12_\"\n",
        "  os.mkdir(folder_path)\n",
        "  os.mkdir(folder_path + \"/seq_cnn\")\n",
        "  os.mkdir(folder_path + \"/img_cnn\")\n",
        "\n",
        "  with open(folder_path + r\"/model_settings.txt\", \"w\") as current_settings:\n",
        "    current_settings.write(f\"ATTRIBUTES: {input_attributes} \\nAMOUNT: {amount} \\nSEED: {seed} \\nBATCH SIZE: {batch_size}\")\n",
        "\n",
        "  with open(folder_path + r\"/epoch_losses.csv\", \"w\", encoding=\"UTF8\", newline=\"\") as epoch_losses:\n",
        "    writer = csv.writer(epoch_losses, delimiter=\";\")\n",
        "    writer.writerow([\"EPOCH\", \"LOSS PER SAMPLE\"])\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "\n",
        "  running_loss = 0.0\n",
        "  for i, data in enumerate(trainloader):\n",
        "\n",
        "    anchors, positives, negatives = data\n",
        "\n",
        "    anchors = anchors.to(device)\n",
        "    anchors = anchors.float()\n",
        "    positives = positives.to(device)\n",
        "    positives = positives.float()\n",
        "    negatives = negatives.to(device)\n",
        "    negatives = negatives.float()\n",
        "\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    anchors = anchors[:, None]\n",
        "    negatives = negatives[:, None]\n",
        "    anchors = seq_cnn(anchors)\n",
        "    negatives = seq_cnn(negatives)\n",
        "    positives = img_cnn(positives)\n",
        "\n",
        "    loss = criterion(anchors, positives, negatives)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    # print(running_loss)\n",
        "    running_loss += loss.item()\n",
        "  \n",
        "  print(f\"\\nEpoch Loss: {running_loss/(amount/batch_size)}\")\n",
        "  losses.append(running_loss/(amount/batch_size))\n",
        "\n",
        "  if enable_checkpoints:\n",
        "    torch.save(seq_cnn.state_dict(), f\"{folder_path}/seq_cnn/SEQ_CNN_epoch_{epoch}\")\n",
        "    torch.save(img_cnn.state_dict(), f\"{folder_path}/img_cnn/IMG_CNN_epoch_{epoch}\")\n",
        "\n",
        "    with open(folder_path + r\"/epoch_losses.csv\", \"a\", encoding=\"UTF8\", newline=\"\") as epoch_losses:\n",
        "      writer = csv.writer(epoch_losses, delimiter=\";\")\n",
        "      writer.writerow([epoch, running_loss/(amount/batch_size)])\n",
        "\n",
        "print(\"Finished training!\")\n",
        "print(losses)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Sequential.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}